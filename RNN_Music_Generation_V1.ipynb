{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d567d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2025 MIT Introduction to Deep Learning. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the MIT License. You may not use this file except in compliance\n",
    "# with the License. Use and/or modification of this code outside of MIT Introduction\n",
    "# to Deep Learning must reference:\n",
    "#\n",
    "# Â© MIT Introduction to Deep Learning\n",
    "# http://introtodeeplearning.com\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "!pip install comet_ml > /dev/null 2>&1\n",
    "import comet_ml\n",
    "#  ENTER YOUR API KEY HERE!! instructions above\n",
    "COMET_API_KEY = \"AMQFF1CTWH6X6ndsIxMozsuTA\"\n",
    "\n",
    "# Import PyTorch and other relevant libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Download and import the MIT Introduction to Deep Learning package\n",
    "!pip install mitdeeplearning --quiet\n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "# Import all remaining packages\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import write\n",
    "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
    "\n",
    "\n",
    "# Check that we are using a GPU, if not switch runtimes\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "# assert torch.cuda.is_available(), \"Please enable GPU from runtime settings\"\n",
    "assert COMET_API_KEY != \"\", \"Please insert your Comet API Key\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf1a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "songs = mdl.lab1.load_training_data()\n",
    "\n",
    "# Print one of the songs to inspect it in greater detail!\n",
    "example_song = songs[0]\n",
    "print(\"\\nExample song: \")\n",
    "print(example_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the ABC notation to audio file and listen to it\n",
    "mdl.lab1.play_song(example_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3277d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join our list of song strings into a single string containing all songs\n",
    "songs_joined = \"\\n\\n\".join(songs)\n",
    "\n",
    "# Find all unique characters in the joined string\n",
    "vocab = sorted(set(songs_joined))\n",
    "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c721af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define numerical representation of text ###\n",
    "\n",
    "# Create a mapping from character to unique index.\n",
    "# For example, to get the index of the character \"d\",\n",
    "#   we can evaluate `char2idx[\"d\"]`.\n",
    "char2idx = {u: i for i, u in enumerate(vocab)}\n",
    "\n",
    "# Create a mapping from indices to characters. This is\n",
    "#   the inverse of char2idx and allows us to convert back\n",
    "#   from unique index to the character in our vocabulary.\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee06606",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{')\n",
    "for char, _ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba96a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectorize the songs string ###\n",
    "\n",
    "''' Write a function to convert the all songs string to a vectorized\n",
    "    (i.e., numeric) representation. Use the appropriate mapping\n",
    "    above to convert from vocab characters to the corresponding indices.\n",
    "\n",
    "  NOTE: the output of the `vectorize_string` function\n",
    "  should be a np.array with `N` elements, where `N` is\n",
    "  the number of characters in the input string\n",
    "'''\n",
    "def vectorize_string(string):\n",
    "  ''''''\n",
    "  return np.array([char2idx[char] for char in string])\n",
    "\n",
    "vectorized_songs = vectorize_string(songs_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e49e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
    "# check that vectorized_songs is a numpy array\n",
    "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Batch definition to create training examples ###\n",
    "\n",
    "def get_batch(vectorized_songs, seq_length, batch_size):\n",
    "    # the length of the vectorized songs string\n",
    "    n = vectorized_songs.shape[0] - 1\n",
    "    # randomly choose the starting indices for the examples in the training batch\n",
    "    idx = np.random.choice(n - seq_length, batch_size)\n",
    "\n",
    "    ''' construct a list of input sequences for the training batch'''\n",
    "    input_batch = np.stack([vectorized_songs[i : i + seq_length] for i in idx])\n",
    "\n",
    "    ''' construct a list of output sequences for the training batch'''\n",
    "    output_batch = np.stack([vectorized_songs[i + 1 : i + seq_length + 1] for i in idx])\n",
    "\n",
    "    # Convert the input and output batches to tensors\n",
    "    x_batch = torch.tensor(input_batch, dtype=torch.long)\n",
    "    y_batch = torch.tensor(output_batch, dtype=torch.long)\n",
    "\n",
    "    return x_batch, y_batch\n",
    "\n",
    "# Perform some simple tests to make sure your batch function is working properly!\n",
    "test_args = (vectorized_songs, 10, 2)\n",
    "x_batch, y_batch = get_batch(*test_args)\n",
    "assert x_batch.shape == (2, 10), \"x_batch shape is incorrect\"\n",
    "assert y_batch.shape == (2, 10), \"y_batch shape is incorrect\"\n",
    "print(\"Batch function works correctly!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
    "\n",
    "for i, (input_idx, target_idx) in enumerate(zip(x_batch[0], y_batch[0])):\n",
    "    print(\"Step {:3d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx.item()])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx.item()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "### Defining the RNN Model ###\n",
    "\n",
    "''' Add LSTM and Linear layers to define the RNN model using nn.Module'''\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Define each of the network layers\n",
    "        # Layer 1: Embedding layer to transform indices into dense vectors\n",
    "        #   of a fixed embedding size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        ''' Layer 2: LSTM with hidden_size `hidden_size`. note: number of layers defaults to 1.\n",
    "         Use the nn.LSTM() module from pytorch.'''\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size) # \n",
    "\n",
    "        ''' Layer 3: Linear (fully-connected) layer that transforms the LSTM output\n",
    "        #   into the vocabulary size.'''\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size) # \n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        # Initialize hidden state and cell state with zeros\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size).to(device),\n",
    "                torch.zeros(1, batch_size, self.hidden_size).to(device))\n",
    "\n",
    "    def forward(self, x, state=None, return_state=False):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if state is None:\n",
    "            state = self.init_hidden(x.size(1), x.device)\n",
    "        out, state = self.lstm(x, state)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out if not return_state else (out, state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model! Build a simple model with default hyperparameters. You\n",
    "#     will get the chance to change these later.\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "hidden_size = 1024\n",
    "batch_size = 8\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMModel(vocab_size, embedding_dim, hidden_size).to(device)\n",
    "\n",
    "# print out a summary of the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with some sample data\n",
    "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "pred = model(x)\n",
    "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ea3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = torch.multinomial(torch.softmax(pred[0], dim=-1), num_samples=1)\n",
    "sampled_indices = sampled_indices.squeeze(-1).cpu().numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1212f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[x[0].cpu()])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the loss function ###\n",
    "\n",
    "# ''' define the compute_loss function to compute and return the loss between\n",
    "#     the true labels and predictions (logits). '''\n",
    "cross_entropy = nn.CrossEntropyLoss() # instantiates the function\n",
    "def compute_loss(labels, logits):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      labels: (batch_size, sequence_length)\n",
    "      logits: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "    Output:\n",
    "      loss: scalar cross entropy loss over the batch and sequence length\n",
    "    \"\"\"\n",
    "\n",
    "    # Batch the labels so that the shape of the labels should be (B * L,)\n",
    "    batched_labels = labels.view(-1)\n",
    "\n",
    "    '''  Batch the logits so that the shape of the logits should be (B * L, V) '''\n",
    "    batched_logits = logits.view(-1, logits.size(-1)) # \n",
    "\n",
    "    ''' Compute the cross-entropy loss using the batched  next characters and predictions'''\n",
    "    loss = cross_entropy(batched_logits, batched_labels) # \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute the loss on the predictions from the untrained model from earlier. ###\n",
    "y.shape  # (batch_size, sequence_length)\n",
    "pred.shape  # (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "''' compute the loss using the true next characters from the example batch\n",
    "    and the predictions from the untrained model several cells above'''\n",
    "example_batch_loss = compute_loss(y, pred) # \n",
    "\n",
    "print(f\"Prediction shape: {pred.shape} # (batch_size, sequence_length, vocab_size)\")\n",
    "print(f\"scalar_loss:      {example_batch_loss.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter setting and optimization ###\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Model parameters:\n",
    "params = dict(\n",
    "  num_training_iterations = 3000,  # Increase this to train longer\n",
    "  batch_size = 8,  # Experiment between 1 and 64\n",
    "  seq_length = 100,  # Experiment between 50 and 500\n",
    "  learning_rate = 5e-3,  # Experiment between 1e-5 and 1e-1\n",
    "  embedding_dim = 256,\n",
    "  hidden_size = 1024,  # Experiment between 1 and 2048\n",
    ")\n",
    "\n",
    "# Checkpoint location:\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a Comet experiment to track our training run ###\n",
    "\n",
    "def create_experiment():\n",
    "  # end any prior experiments\n",
    "  if 'experiment' in locals():\n",
    "    experiment.end()\n",
    "\n",
    "  # initiate the comet experiment for tracking\n",
    "  experiment = comet_ml.Experiment(\n",
    "                  api_key=COMET_API_KEY,\n",
    "                  project_name=\"6S191_Lab1_Part2\")\n",
    "  # log our hyperparameters, defined above, to the experiment\n",
    "  for param, value in params.items():\n",
    "    experiment.log_parameter(param, value)\n",
    "  experiment.flush()\n",
    "\n",
    "  return experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training loop\n",
    "### Define optimizer and training operation ###\n",
    "\n",
    "''' instantiate a new LSTMModel model for training using the hyperparameters\n",
    "    created above.'''\n",
    "model = LSTMModel(vocab_size,\n",
    "    params[\"embedding_dim\"],\n",
    "    params[\"hidden_size\"])\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(device)\n",
    "\n",
    "''' instantiate an optimizer with its learning rate.\n",
    "  Checkout the PyTorch website for a list of supported optimizers.\n",
    "  https://pytorch.org/docs/stable/optim.html\n",
    "  Try using the Adam optimizer to start.'''\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"learning_rate\"]) # \n",
    "\n",
    "def train_step(x, y):\n",
    "  # Set the model's mode to train\n",
    "  model.train()\n",
    "\n",
    "  # Zero gradients for every step\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # Forward pass\n",
    "  ''' feed the current input into the model and generate predictions'''\n",
    "  y_hat = model(x)\n",
    "\n",
    "  # Compute the loss\n",
    "  ''' compute the loss!'''\n",
    "  loss = compute_loss(y, y_hat)\n",
    "\n",
    "  # Backward pass\n",
    "  ''' complete the gradient computation and update step.\n",
    "    Remember that in PyTorch there are two steps to the training loop:\n",
    "    1. Backpropagate the loss\n",
    "    2. Update the model parameters using the optimizer\n",
    "  '''\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  return loss\n",
    "\n",
    "##################\n",
    "# Begin training!#\n",
    "##################\n",
    "\n",
    "history = []\n",
    "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
    "experiment = create_experiment()\n",
    "\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
    "for iter in tqdm(range(params[\"num_training_iterations\"])):\n",
    "\n",
    "    # Grab a batch and propagate it through the network\n",
    "    x_batch, y_batch = get_batch(vectorized_songs, params[\"seq_length\"], params[\"batch_size\"])\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    x_batch = torch.tensor(x_batch, dtype=torch.long).to(device)\n",
    "    y_batch = torch.tensor(y_batch, dtype=torch.long).to(device)\n",
    "\n",
    "    # Take a train step\n",
    "    loss = train_step(x_batch, y_batch)\n",
    "\n",
    "    # Log the loss to the Comet interface\n",
    "    experiment.log_metric(\"loss\", loss.item(), step=iter)\n",
    "\n",
    "    # Update the progress bar and visualize within notebook\n",
    "    history.append(loss.item())\n",
    "    plotter.plot(history)\n",
    "\n",
    "    # Save model checkpoint\n",
    "    if iter % 100 == 0:\n",
    "        torch.save(model.state_dict(), checkpoint_prefix)\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(model.state_dict(), checkpoint_prefix)\n",
    "experiment.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f05b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction of a generated song ###\n",
    "\n",
    "def generate_text(model, start_string, generation_length=1000):\n",
    "  # Evaluation step (generating ABC text using the learned RNN model)\n",
    "\n",
    "  ''' convert the start string to numbers (vectorize)'''\n",
    "  input_idx = [char2idx[start_string[-1]]] # \n",
    "  input_idx = torch.tensor([input_idx], dtype=torch.long).to(device)\n",
    "\n",
    "  # Initialize the hidden state\n",
    "  state = model.init_hidden(input_idx.size(0), device)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "  tqdm._instances.clear()\n",
    "\n",
    "  for i in tqdm(range(generation_length)):\n",
    "    ''' evaluate the inputs and generate the next character predictions'''\n",
    "    predictions, hidden_state = model(input_idx, state, return_state=True) # \n",
    "\n",
    "    # Remove the batch dimension\n",
    "    predictions = predictions.squeeze(0)\n",
    "\n",
    "    ''' use a multinomial distribution to sample over the probabilities'''\n",
    "    input_idx = torch.multinomial(torch.softmax(predictions[-1], dim=-1), num_samples=1).unsqueeze(0) # \n",
    "\n",
    "    ''' add the predicted character to the generated text!'''\n",
    "    # Hint: consider what format the prediction is in vs. the output\n",
    "    next_char = idx2char[input_idx.item()]\n",
    "    text_generated.append(next_char) # \n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce49321",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Use the model and the function defined above to generate ABC format text of length 1000!\n",
    "    As you may notice, ABC files start with \"X\" - this may be a good start string.'''\n",
    "my_start_string = (\n",
    "    \"X:1\\n\"\n",
    "    \"T:Happy\\n\"\n",
    "    \"M:4/4\\n\"\n",
    "    \"L:1/8\\n\"\n",
    "    \"K:C\\n\"\n",
    "    \"|: CDEF GABc | cBAG FEDC :|\\n\"\n",
    ")\n",
    "generated_text = generate_text(model, start_string=my_start_string, generation_length=1000) # \n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio generation and saving\n",
    "### Play back generated songs ###\n",
    "\n",
    "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
    "\n",
    "for i, song in enumerate(generated_songs):\n",
    "  # Synthesize the waveform from a song\n",
    "  waveform = mdl.lab1.play_song(song)\n",
    "\n",
    "  # If its a valid song (correct syntax), lets play it!\n",
    "  if waveform:\n",
    "    print(\"Generated song\", i)\n",
    "    ipythondisplay.display(waveform)\n",
    "\n",
    "    numeric_data = np.frombuffer(waveform.data, dtype=np.int16)\n",
    "    wav_file_path = f\"output_{i}.wav\"\n",
    "    write(wav_file_path, 88200, numeric_data)\n",
    "\n",
    "    # save your song to the Comet interface -- you can access it there\n",
    "    experiment.log_asset(wav_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbeaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when done, end the comet experiment\n",
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
